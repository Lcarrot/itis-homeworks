# MPI #
## Задачи: ##

:white_check_mark: 1. Hello world из всех процессов  
:white_check_mark: 2. Maксимум массива  
:white_check_mark: 3. Вычисление числа Пи методом Монте-Карло     
:white_check_mark: 4. Среднее арифметическое среди положительных чисел массива   
:white_check_mark: 5. Скалярное произведение  
:white_check_mark: 6. Maxmin матрицы  
:white_check_mark: 7. Умножение матрицы на вектор при разделении данных по столбцам  
:white_check_mark: 8. Scatter и Gather через Send и Recv   
:white_check_mark: 9. Инвертировать массив  
:white_check_mark: 10. Время передачи для разных Send-oв        
:white_check_mark: 11. Циклическая передача данных    
:white_check_mark: 19. Быстрая сортировка с выбором ведущего элемента  

## Спецификации задач ##
1. уметь запускать MPI  
2.  уметь использовать что-то из send, recv,  bcast, reduce  
3.  метод Монте-Карло для получения Пи, понимается как генерирование случайной последовательности точек из квадрата со сторонами 2 и центром в центре координат. Доля точек попавших в круг с радиусом один умноженная на 4 должна стремиться к числу Пи. Распараллеливание заключается в сбалансированном распределении итераций по процессам.  
4. Распределение данных через scatterv. Два mpi_reduce подряд не использовать.  
5. Распределение данных через scatterv. Есть два массива – надо найти суммы произведений соответствующих координат.  
6. Найти седловую точку матрицы. Распределение данных через scatterv. Каждый процесс получает какое-то количество строк матрицы. Находит для каждой строки минимум и выбирает из  них максимальный. Далее из локальных максимумов выбирает глобальный. Проверить совпадают ли maxmin и minmax.  
7. На одном процессе заполняется матрица и вектор. Каждый процесс получает несколько столбцов матрицы и столько же элементов вектора. Рассчитывает частичную сумму результирующего вектора.  ci = A i,j * b j   для  j-го столбца. Если столбцов несколько, то cj суммируются. Далее все частичные суммы собираются в результат.  
8. На одном процессе есть массив из n чисел. Выводим его. При помощи send, recv раздаем всем процессам по n/size чисел. Свою часть так же копируем в другой массив  размера n/size.  Выводим номер каждого процесса и его часть массива. Далее при помощи send, recv собираем все части массива на каком-либо процессе в новый массив размера n.  Выводим его.  
9. Перевернуть массив. Работа процессов должна быть сбалансирована. Можно использовать как и Scatterv, Gatherv, так и  Send, Recv.  
10. Программу тестируем на двух процессах. Используем Send, Ssend, Bsend и Rsend  - передаем какой-либо длинный массив или строку второму процессу, и получаем  обратно. Замеряем время потраченные на эти операции.  
11. В коммуникаторе передаем сообщение от одного процесса другому с нулевого до size-1. Последний процесс отправляет сообщение нулевому. На каждом процессе сообщение изменяется, если это число, то можно прибавлять или умножать на что-то.   
